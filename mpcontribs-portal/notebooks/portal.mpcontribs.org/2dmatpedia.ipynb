{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gzip, json\n",
    "from time import sleep, time\n",
    "from mpcontribs.client import Client\n",
    "from pymatgen import Structure, MPRester\n",
    "from urllib.request import urlretrieve\n",
    "from monty.json import MontyDecoder\n",
    "from itertools import groupby\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = '2dmatpedia'\n",
    "client = Client('your-api-key-here')\n",
    "mpr = MPRester()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create project (once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_public = True\n",
    "info = {\n",
    "    'project': project,\n",
    "    'is_public': is_public,\n",
    "    'title': '2DMatPedia',\n",
    "    'long_title': '2D Materials Encyclopedia',\n",
    "    'owner': 'migueldiascosta@nus.edu.sg',\n",
    "    'authors': 'M. Dias Costa, F.Y. Ping, Z. Jun',\n",
    "    'description': ' '.join('''\n",
    "    We start from the around 80000 inorganic compounds in the Materials Project database. A geometry-based\n",
    "    algorithm [PRL] was used to identify layered structures among these compounds. Two-dimensional (2D)\n",
    "    materials were theoretically exfoliated by extracting one cluster in the standard conventional unit cell\n",
    "    of the layered structures screened in the above steps. A 20 Å vacuum along the c axis was imposed to\n",
    "    minimize the interactions of image slabs by periodic condition. Structure matcher tools from Pymatgen were\n",
    "    used to find duplicates of the exfoliated 2D materials. The standard workflow developed by the Materials\n",
    "    Project was used to perform high-throughput calculations for all the layered bulk and 2D materials screened\n",
    "    in this project. The calculations were performed by density functional theory as implemented in the Vienna\n",
    "    Ab Initio Simulation Package (VASP) software with Perdew-Burke-Ernzerhof (PBE) approximation for the\n",
    "    exchange-correlation functional and the frozen-core all-electron projector-augmented wave (PAW) method for\n",
    "    the electron-ion interaction. The cutoff energy for the plane wave expansion was set to 520 eV.\n",
    "    '''.replace('\\n', '').split()),\n",
    "    'urls': {\n",
    "        'WWW': 'http://www.2dmatpedia.org',\n",
    "        'PRL': 'https://doi.org/10.1103/PhysRevLett.118.106101'    \n",
    "    }\n",
    "}\n",
    "# client.projects.create_entry(project=info).result()\n",
    "# client.projects.get_entry(pk=project, _fields=['_all']).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"file\": \"http://www.2dmatpedia.org/static/db.json.gz\",\n",
    "    \"details\": \"http://www.2dmatpedia.org/2dmaterials/doc/{}\",\n",
    "    'columns': {\n",
    "        'material_id': {'name': 'details'},\n",
    "        'exfoliation_energy_per_atom': {'name': 'Eₓ', 'unit': 'eV'},\n",
    "        'energy_per_atom': {'name': 'E', 'unit': 'meV'},\n",
    "        'energy_vdw_per_atom': {'name': 'ΔE|vdW', 'unit': 'meV'},\n",
    "        'bandgap': {'name': 'ΔE', 'unit': 'meV'},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []  # as read from raw files\n",
    "dbfile = config['file'].rsplit('/')[-1]\n",
    "if not os.path.exists(dbfile):\n",
    "    print('downloading', dbfile, '...')\n",
    "    urlretrieve(config['file'], dbfile)\n",
    "\n",
    "with gzip.open(dbfile, 'rb') as f:\n",
    "    for line in f:\n",
    "        raw_data.append(json.loads(line, cls=MontyDecoder))\n",
    "\n",
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data dict from raw data entry\n",
    "def get_data(rd, identifier):\n",
    "    data = {}\n",
    "    for k, col in config['columns'].items():\n",
    "        hdr, unit = col['name'], col.get('unit')\n",
    "        if k == 'material_id':\n",
    "            data[hdr] = config[hdr].format(rd[k])\n",
    "        elif k in rd:\n",
    "            if unit:\n",
    "                try:\n",
    "                    float(rd[k])\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            data[hdr] = f'{rd[k]} {unit}' if unit else rd[k]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_sorted = sorted(raw_data, key=itemgetter('source_id'))\n",
    "raw_data_grouped = {}\n",
    "\n",
    "for task_id, objects in groupby(raw_data_sorted, key=itemgetter('source_id')):\n",
    "    raw_data_grouped[task_id] = list(objects)        \n",
    "\n",
    "print(len(raw_data_sorted), len(raw_data_grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions = {}\n",
    "for idx, (task_id, objects) in enumerate(raw_data_grouped.items()):  \n",
    "    if not idx%500:\n",
    "        print(idx, task_id)\n",
    "    \n",
    "    valid = bool(task_id.startswith('mp-') or task_id.startswith('mvc-'))\n",
    "    if valid and task_id not in contributions:\n",
    "        contrib = {'project': project, 'is_public': is_public, 'identifier': task_id, 'data': {}}\n",
    "        structures = []\n",
    "        names = set()\n",
    "        for j, d in enumerate(objects):\n",
    "            structure = d['structure']\n",
    "            comp = d['structure'].composition.reduced_formula\n",
    "            name = f'{comp}|{j}' if comp in names else comp        \n",
    "            names.add(name)\n",
    "            structure = d['structure'].as_dict()\n",
    "            structure.update({'label': '2D', 'name': name, 'is_public': is_public})\n",
    "            structures.append(structure)\n",
    "            label = f'2D|{j}'\n",
    "            contrib['data'][label] = get_data(d, task_id)\n",
    "            contrib['data'][label]['formula'] = comp\n",
    "\n",
    "        contributions[task_id] = {'contrib': contrib, 'structures': structures}\n",
    "\n",
    "print(len(contributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def chunks(data, SIZE=100):\n",
    "    it = iter(data)\n",
    "    for i in range(0, len(data), SIZE):\n",
    "        if isinstance(data, dict):\n",
    "            yield {k: data[k] for k in islice(it, SIZE)}\n",
    "        else:\n",
    "            yield data[i:i+SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entries():\n",
    "    return [c['id'] for c in client.contributions.get_entries(\n",
    "        project=project, _limit=100, _fields=['id']\n",
    "    ).result()['data']]\n",
    "\n",
    "cids = get_entries()\n",
    "while cids:\n",
    "    cnt = client.contributions.delete_entries(id__in=cids).result()['count']\n",
    "    print(cnt, 'contributions deleted')\n",
    "    cids = get_entries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(chunks(contributions)):\n",
    "    contribs = [c['contrib'] for c in chunk.values()]\n",
    "    created = client.contributions.create_entries(contributions=contribs).result()\n",
    "    print(i, created['count'], 'contributions created')    \n",
    "    \n",
    "    create_structures = []\n",
    "    for contrib in created['data']:\n",
    "        identifier = contrib['identifier']\n",
    "        for s in chunk[identifier]['structures']:\n",
    "            s['contribution'] = contrib['id']\n",
    "            create_structures.append(s)\n",
    "         \n",
    "    print('submit', len(create_structures), 'structures ...')\n",
    "    for j, subchunk in enumerate(chunks(create_structures)):\n",
    "        created = client.structures.create_entries(structures=subchunk).result()\n",
    "        print(j, created['count'], 'structures created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
