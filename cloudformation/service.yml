AWSTemplateFormatVersion: '2010-09-09'
Description: app service
Parameters:
  PipelineName:
    Type: String
  EnvironmentName:
    Type: String
    Description: A name for the environment that this cloudformation will be part of.
                 Used to locate other resources in the same environment.
  Repository:
    Type: String
    Description: ECR repository name
  MongoHost:
    Type: String
    Description: MongoDB host that the app connects to.
  AwsAccessKeyId:
    Type: String
  AwsSecretAccessKey:
    Type: String
  SnsAdminTopicArn:
    Type: String
  ServiceName:
    Type: String
    Default: app
    Description: A name for the service
  Tag:
    Type: String
    Description: short git tag used for image builds
  ApiCname:
    Type: String
    Default: 'api.mpcontribs.org'
    Description: CNAME for the API
  ApiPort:
    Type: String
    Default: '5000'
    Description: Port for the API
  MpcontribsDbName:
    Type: String
    Default: 'mpcontribs'
    Description: MPContribs DB name on Atlas (mongodb.com)
  PortalCname:
    Type: String
    Default: 'portal.mpcontribs.org'
    Description: CNAME for the Portal
  PortalPort:
    Type: String
    Default: '8080'
    Description: Port for the Portal
  DdApiKey:
    Type: String

Resources:
  # A log group for storing the container logs for this service
  LogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Join ['-', [!Ref 'PipelineName', !Ref 'EnvironmentName', 'service', !Ref 'ServiceName']]

  # A role for the service so it can access the tables
  AppServiceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Effect: Allow
          Principal:
            Service: "ecs-tasks.amazonaws.com"
          Action: ['sts:AssumeRole']
      Path: /
      Policies:
      - PolicyName: app-policy
        PolicyDocument:
          Statement:
          - Effect: Allow
            Action:
              - "s3:PutObject"
              - "s3:GetObject"
              - "s3:ListBucket"
              - "ecr:BatchCheckLayerAvailability"
              - "ecr:BatchGetImage"
              - "ecr:GetDownloadUrlForLayer"
              - "ecr:GetAuthorizationToken"
            Resource:
              - "*"

  # The task definition. This is a simple metadata description of what
  # container to run, and what resource requirements it has.
  TaskDefinition:
    Type: AWS::ECS::TaskDefinition
    Properties:
      Family: !Ref 'ServiceName'
      Cpu: 2048
      Memory: 4096
      NetworkMode: awsvpc
      RequiresCompatibilities:
        - FARGATE
      ExecutionRoleArn:
        Fn::ImportValue:
          !Join [':', [!Ref 'PipelineName', !Ref 'EnvironmentName', 'ECSTaskExecutionRole']]
      TaskRoleArn: !Ref 'AppServiceRole'
      ContainerDefinitions:
        - Name: api
          MemoryReservation: 500
          Image: !Join ['', [
            !Ref 'AWS::AccountId', '.dkr.ecr.', !Ref 'AWS::Region', '.amazonaws.com/',
            !Ref 'Repository', ':', !Ref 'PipelineName', '-', !Ref 'EnvironmentName', '-',
            !Ref 'Tag', '-api'
          ]]
          DockerLabels:
            my.custom.label.service: !Join ['-', [
              !Ref 'PipelineName', !Ref 'EnvironmentName', !Ref 'ServiceName'
            ]]
            com.datadoghq.ad.instances: !Sub |
              [{"host": "%%host%%", "port": "${ApiPort}"}]
            com.datadoghq.ad.check_names: "[\"ecs_fargate\"]"
            com.datadoghq.ad.init_configs: "[{}]"
          DependsOn:
            - Condition: START
              ContainerName: chrome
            - Condition: START
              ContainerName: gateway
            - Condition: START
              ContainerName: datadog
          Environment:
            - Name: MPCONTRIBS_API_HOST
              Value: !Join [':', ['localhost', !Ref 'ApiPort']]
            - Name: MPCONTRIBS_MONGO_HOST
              Value: !Ref 'MongoHost'
            - Name: API_CNAME
              Value: !Ref 'ApiCname'
            - Name: API_PORT
              Value: !Ref 'ApiPort'
            - Name: PORTAL_CNAME
              Value: !Ref 'PortalCname'
            - Name: PORTAL_PORT
              Value: !Ref 'PortalPort'
            - Name: MPCONTRIBS_DB_NAME
              Value: !Ref 'MpcontribsDbName'
            - Name: AWS_ACCESS_KEY_ID
              Value: !Ref 'AwsAccessKeyId'
            - Name: AWS_SECRET_ACCESS_KEY
              Value: !Ref 'AwsSecretAccessKey'
            - Name: AWS_SNS_TOPIC_ARN
              Value: !Ref 'SnsAdminTopicArn'
            - Name: AWS_DEFAULT_REGION
              Value: !Ref 'AWS::Region'
            - Name: AWS_REGION
              Value: !Ref 'AWS::Region'
            - Name: REDIS_ADDRESS
              Value:
                Fn::ImportValue:
                    !Join [':', [!Ref 'PipelineName', !Ref 'EnvironmentName', 'ElastiCacheAddress']]
            - Name: DD_TRACE_AGENT_PORT
              Value: 8126
            - Name: DD_TRACE_AGENT_HOSTNAME
              Value: localhost
          PortMappings:
            - ContainerPort: !Ref 'ApiPort'
          LogConfiguration:
            LogDriver: 'awslogs'
            Options:
              awslogs-group: !Join ['-', [!Ref 'PipelineName', !Ref 'EnvironmentName', 'service', !Ref 'ServiceName']]
              awslogs-region: !Ref 'AWS::Region'
              awslogs-stream-prefix: !Ref 'ServiceName'
        - Name: chrome
          MemoryReservation: 100
          Image: !Join ['', [
            !Ref 'AWS::AccountId', '.dkr.ecr.', !Ref 'AWS::Region', '.amazonaws.com/',
            !Ref 'Repository', ':', !Ref 'PipelineName', '-', !Ref 'EnvironmentName', '-',
            !Ref 'Tag', '-chrome'
          ]]
          DockerLabels:
            my.custom.label.service: !Join ['-', [
              !Ref 'PipelineName', !Ref 'EnvironmentName', !Ref 'ServiceName'
            ]]
            com.datadoghq.ad.instances: !Sub |
              [{"host": "%%host%%", "port": "${ApiPort}"}]
            com.datadoghq.ad.check_names: "[\"ecs_fargate\"]"
            com.datadoghq.ad.init_configs: "[{}]"
          Environment:
            - Name: START_XVFB
              Value: false
            - Name: DD_TRACE_AGENT_PORT
              Value: 8126
            - Name: DD_TRACE_AGENT_HOSTNAME
              Value: localhost
          PortMappings:
            - ContainerPort: 4444
          LogConfiguration:
            LogDriver: 'awslogs'
            Options:
              awslogs-group: !Join ['-', [!Ref 'PipelineName', !Ref 'EnvironmentName', 'service', !Ref 'ServiceName']]
              awslogs-region: !Ref 'AWS::Region'
              awslogs-stream-prefix: !Ref 'ServiceName'
        - Name: gateway
          MemoryReservation: 250
          Image: !Join ['', [
            !Ref 'AWS::AccountId', '.dkr.ecr.', !Ref 'AWS::Region', '.amazonaws.com/',
            !Ref 'Repository', ':', !Ref 'PipelineName', '-', !Ref 'EnvironmentName', '-',
            !Ref 'Tag', '-gateway'
          ]]
          DockerLabels:
            my.custom.label.service: !Join ['-', [
              !Ref 'PipelineName', !Ref 'EnvironmentName', !Ref 'ServiceName'
            ]]
            com.datadoghq.ad.instances: !Sub |
              [{"host": "%%host%%", "port": "${ApiPort}"}]
            com.datadoghq.ad.check_names: "[\"ecs_fargate\"]"
            com.datadoghq.ad.init_configs: "[{}]"
          Environment:
            - Name: KG_ALLOW_ORIGIN
              Value: '*'
            - Name: MPCONTRIBS_API_HOST
              Value: !Join [':', ['localhost', !Ref 'ApiPort']]
            - Name: DD_TRACE_AGENT_PORT
              Value: 8126
            - Name: DD_TRACE_AGENT_HOSTNAME
              Value: localhost
          PortMappings:
            - ContainerPort: 8888
          LogConfiguration:
            LogDriver: 'awslogs'
            Options:
              awslogs-group: !Join ['-', [!Ref 'PipelineName', !Ref 'EnvironmentName', 'service', !Ref 'ServiceName']]
              awslogs-region: !Ref 'AWS::Region'
              awslogs-stream-prefix: !Ref 'ServiceName'
        - Name: portal
          MemoryReservation: 350
          Image: !Join ['', [
            !Ref 'AWS::AccountId', '.dkr.ecr.', !Ref 'AWS::Region', '.amazonaws.com/',
            !Ref 'Repository', ':', !Ref 'PipelineName', '-', !Ref 'EnvironmentName', '-',
            !Ref 'Tag', '-portal'
          ]]
          DockerLabels:
            my.custom.label.service: !Join ['-', [
              !Ref 'PipelineName', !Ref 'EnvironmentName', !Ref 'ServiceName'
            ]]
            com.datadoghq.ad.instances: !Sub |
              [{"host": "%%host%%", "port": "${ApiPort}"}]
            com.datadoghq.ad.check_names: "[\"ecs_fargate\"]"
            com.datadoghq.ad.init_configs: "[{}]"
          Environment:
            - Name: NODE_ENV
              Value: production
            - Name: MPCONTRIBS_API_HOST
              Value: !Join [':', ['localhost', !Ref 'ApiPort']]
            - Name: API_CNAME
              Value: !Ref 'ApiCname'
            - Name: API_PORT
              Value: !Ref 'ApiPort'
            - Name: PORTAL_CNAME
              Value: !Ref 'PortalCname'
            - Name: PORTAL_PORT
              Value: !Ref 'PortalPort'
            - Name: AWS_REGION
              Value: !Ref 'AWS::Region'
            - Name: DD_TRACE_AGENT_PORT
              Value: 8126
            - Name: DD_TRACE_AGENT_HOSTNAME
              Value: localhost
          DependsOn:
            - Condition: START
              ContainerName: api
          PortMappings:
            - ContainerPort: !Ref 'PortalPort'
          LogConfiguration:
            LogDriver: 'awslogs'
            Options:
              awslogs-group: !Join ['-', [!Ref 'PipelineName', !Ref 'EnvironmentName', 'service', !Ref 'ServiceName']]
              awslogs-region: !Ref 'AWS::Region'
              awslogs-stream-prefix: !Ref 'ServiceName'
        - Name: datadog
          MemoryReservation: 50
          Image: !Join ['', [
            !Ref 'AWS::AccountId', '.dkr.ecr.', !Ref 'AWS::Region', '.amazonaws.com/',
            !Ref 'Repository', ':', !Ref 'PipelineName', '-', !Ref 'EnvironmentName', '-',
            !Ref 'Tag', '-datadog'
          ]]
          Environment:
            - Name: DD_API_KEY
              Value: !Ref 'DdApiKey'
            - Name: DD_APM_ENABLED
              Value: true
            - Name: DD_SYSTEM_PROBE_ENABLED
              Value: true
            - Name: DD_PROCESS_AGENT_ENABLED
              Value: true
            - Name: ECS_FARGATE
              Value: true
            - Name: DD_DOGSTATSD_NON_LOCAL_TRAFFIC
              Value: true
            - Name: DD_DOCKER_LABELS_AS_TAGS
              Value: "{\"my.custom.label.service\":\"service\"}"
            - Name: DD_RECEIVER_PORT
              Value: 8126
            - Name: DD_DD_URL
              Value: https://pvtlink.agent.datadoghq.com
            - Name: DD_LOGS_CONFIG_USE_HTTP
              Value: true
            - Name: DD_LOGS_CONFIG_LOGS_DD_URL
              Value: "pvtlink.logs.datadoghq.com:443"
          LogConfiguration:
            LogDriver: 'awslogs'
            Options:
              awslogs-group: !Join ['-', [!Ref 'PipelineName', !Ref 'EnvironmentName', 'service', !Ref 'ServiceName']]
              awslogs-region: !Ref 'AWS::Region'
              awslogs-stream-prefix: !Ref 'ServiceName'

  # The service. The service is a resource which allows you to run multiple
  # copies of a type of task, and gather up their logs and metrics, as well
  # as monitor the number of running tasks and replace any that have crashed
  Service:
    Type: AWS::ECS::Service
    Properties:
      ServiceName: !Ref 'ServiceName'
      Cluster:
        Fn::ImportValue:
          !Join [':', [!Ref 'PipelineName', !Ref 'EnvironmentName', 'ClusterName']]
      LaunchType: FARGATE
      PlatformVersion: 1.4.0
      DesiredCount: 2
      NetworkConfiguration:
        AwsvpcConfiguration:
          SecurityGroups:
            - Fn::ImportValue:
                !Join [':', [!Ref 'PipelineName', !Ref 'EnvironmentName', 'PrivateSecurityGroup']]
          Subnets:
            - Fn::ImportValue:
                !Join [':', [!Ref 'PipelineName', !Ref 'EnvironmentName', 'PrivateSubnetOne']]
            - Fn::ImportValue:
                !Join [':', [!Ref 'PipelineName', !Ref 'EnvironmentName', 'PrivateSubnetTwo']]
      TaskDefinition: !Ref 'TaskDefinition'
